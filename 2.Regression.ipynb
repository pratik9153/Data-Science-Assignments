{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e74fc10-f7a4-44c7-8a4d-6959045b7fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. Explain the concept of R-squared in linear regression models. How is it calculated, and what does it\n",
    "#represent?\n",
    "\n",
    "R-squared measure how well the regression model fits the data , indicating the proportion of variance explained by \n",
    "independent variable.\n",
    "\n",
    "#calculate R aquare \n",
    "\n",
    "R-squared = SSR/SStotal\n",
    "\n",
    "It represent the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc329c7d-e246-46f9-a6b6-cbbd637efb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. Define adjusted R-squared and explain how it differs from the regular R-squared.\n",
    "\n",
    "Adjusted R-squared is refer to adjust r-square for the number of predictor , providing more accurate measured of \n",
    "model fit .\n",
    "\n",
    "In R-square if you add a feature the value of R-square will increased no matter feature is important or not , on other\n",
    "hand in Adjusted R-square if you add a feature that is not important then the value will decreased.\n",
    "\n",
    "#Adjusted r-square\n",
    "  \n",
    "    ( 1-(1-r2)(N-1))/(N-P-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe43d1b-9c6e-400c-9a65-c4c8006b532c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. When is it more appropriate to use adjusted R-squared?\n",
    "\n",
    "Adjusted R-squared is preferable when comparing models with different numbers of predictors, penalizing for added \n",
    "predictors to avoid overstating model fit when additional features may not improve prediction significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7297f13e-9393-4d61-884a-90a1b4b40bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. What are RMSE, MSE, and MAE in the context of regression analysis? How are these metrics\n",
    "#calculated, and what do they represent?\n",
    "\n",
    "MSE : Mean Squared Error is a measure of average squared difference between predicted point and actual point.\n",
    "MAE : Mean Absolute Error is a measure of average absolute difference between predicted point and actual point.\n",
    "RMSE : Root Mean Squared Error represents the root of MSE , providing an interpretable measured in same units as the\n",
    "target variable.\n",
    "\n",
    "MSE=1/n ∑i=1n (yi−y^i)2\n",
    "MAE=1/n ∑i=1n ∣yi−y^i∣\n",
    "RMSE = Root of MSE\n",
    "#represent \n",
    "They represents the error between predicted point and actual point . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa3a25c-d985-47d6-9608-e276c86ab44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. Discuss the advantages and disadvantages of using RMSE, MSE, and MAE as evaluation metrics in\n",
    "#regression analysis.\n",
    "\n",
    "ADVANTAGES :\n",
    "    MSE :\n",
    "        It is differentiable\n",
    "        It has only one local and global minima\n",
    "    MAE :\n",
    "        It is robust to outliers\n",
    "        It is in same unit \n",
    "    RMSE :\n",
    "        It is in same unit\n",
    "        It is differentiable\n",
    "DISADVANTAGES:\n",
    "    MSE :\n",
    "        It is not robust to ouliers \n",
    "        It is not in same unit \n",
    "    MAE :\n",
    "        Coverngence takes more time \n",
    "    RMSE :\n",
    "        It is not robust to ouliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5897c3e1-a6db-41d3-983d-ec1a215083a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6. Explain the concept of Lasso regularization. How does it differ from Ridge regularization, and when is\n",
    "#it more appropriate to use?\n",
    "\n",
    "Lasso regularization is linear regression methods that add penalty to the absolute of coefficients and shrinking \n",
    "less important feature coefficients to zero.\n",
    "\n",
    "on other hand , ridge regularization is linear regression methods that add penalty for large coefficients to prevent \n",
    "overfitting.\n",
    "\n",
    "in lasso regularization , when the value of lambda increased then value of theta will decreased , the value of theta \n",
    "will zero\n",
    "\n",
    "in ridge regularization , when the value of lambda increase then value of theta will decreased , but value of theta\n",
    "can not be zero\n",
    "\n",
    "It is appropriate to use in feature selection , when you have have lots of features in your dataset but some of the\n",
    "feature are not important then it help you select important feature ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c986a031-9a97-43c3-a88d-b86dbe044e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7. How do regularized linear models help to prevent overfitting in machine learning? Provide an\n",
    "#example to illustrate.\n",
    "\n",
    "Regularized linear models help to prevent overfitting in machine learning by adding penalty to large coefficient\n",
    "that prevent overfitting .\n",
    "\n",
    "example : Ridge regression add L2 penalty , preventing overfitting by shrinking coefficients towards zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb53365-c3ea-439b-a984-3927c14b226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8. Discuss the limitations of regularized linear models and explain why they may not always be the best\n",
    "#choice for regression analysis.\n",
    "\n",
    "Regularized linear models may struggle with feature selection and fail when relationships are highly nonlinear.\n",
    "In such cases, more flexible models like decision trees or neural networks may offer better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd24b446-5925-4a85-9920-855dbf6f22df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9. You are comparing the performance of two regression models using different evaluation metrics.\n",
    "#Model A has an RMSE of 10, while Model B has an MAE of 8. Which model would you choose as the better\n",
    "#performer, and why? Are there any limitations to your choice of metric?\n",
    "\n",
    "I would choose Model B as the better performer because it has a lower MAE, indicating that its predictions are, \n",
    "on average, closer to the actual values compared to Model A. However, MAE doesn't penalize large errors as heavily \n",
    "as RMSE, so it may overlook outliers or extreme errors.\n",
    "\n",
    "Yes, MAE and RMSE may not capture all aspects of model performance, such as sensitivity to outliers or asymmetry \n",
    "in errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4408f83e-9ba6-44e9-93e7-65640bb85cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q10. You are comparing the performance of two regularized linear models using different types of\n",
    "#regularization. Model A uses Ridge regularization with a regularization parameter of 0.1, while Model B\n",
    "#uses Lasso regularization with a regularization parameter of 0.5. Which model would you choose as the\n",
    "#better performer, and why? Are there any trade-offs or limitations to your choice of regularization\n",
    "#method?\n",
    "\n",
    "\n",
    "It depends on the specific dataset and objectives. Generally, if feature selection is crucial, Lasso (Model B)\n",
    "might be preferred due to its ability to shrink coefficients to zero, effectively performing feature selection.\n",
    "However, Ridge (Model A) might be better for multicollinear data as it does not fully eliminate correlated features.\n",
    "A trade-off exists between bias and variance; Lasso tends to result in sparser models but can be more sensitive to \n",
    "outliers compared to Ridge."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
